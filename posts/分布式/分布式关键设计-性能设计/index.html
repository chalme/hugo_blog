<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>分布式关键设计 性能设计 | Chalme</title><meta name=keywords content="分布式架构,笔记"><meta name=description content="缓存 基本上来说，在分布式系统中最耗性能的地方就是最后端的数据库了。
一般来说，只要小心维护好，数据库四种操作（select、update、insert 和 delete）中的三个写操作 insert、update 和 delete 不太会出现性能问题（insert 一般不会有性能问题，update 和 delete 一般会有主键，所以也不会太慢）。除非索引建得太多，而数据库里的数据又太多，这三个操作才会变慢。 绝大多数情况下，select 是出现性能问题最大的地方。一方面，select 会有很多像 join、group、order、like 等这样丰富的语义，而这些语义是非常耗性能的；另一方面，大多数应用都是读多写少，所以加剧了慢查询的问题。 分布式系统中远程调用也会消耗很多资源，因为网络开销会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不需要太实时的数据）下，使用缓存是非常必要的事情。 设计的重点：
在分布式架构下，一般都需要一个外部的缓存集群。关于这个缓存集群，你需要保证的是内存要足够大，网络带宽也要好，因为缓存本质上是个内存和 IO 密集型的应用。 缓存的好坏要看命中率。缓存的命中率高说明缓存有效，一般来说命中率到 80% 以上就算很高了。当然，有的网络为了追求更高的性能，要做到 95% 以上，甚至可能会把数据库里的数据几乎全部装进缓存中。 缓存是通过牺牲强一致性来提高性能的，这世上任何事情都不是免费的 缓存数据的时间周期也需要好好设计 使用缓存的时候，一般会使用 LRU 策略 缓存是提高性能最好的方式，一般来说，缓存有以下三种模式。
Cache Aside 更新模式 失效：应用程序先从 Cache 取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 Cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。
当然，最好还是为缓存设置好过期时间。
为什么不去直接更新？ 主要是怕两个并发的写操作导致脏数据。
Cache Aside 就不会有并发问题了？ 比如，一个是读操作，但是没有命中缓存，就会到数据库中取数据。而此时来了一个写操作，写完数据库后，让缓存失效，然后之前的那个读操作再把老的数据放进去，所以会造成脏数据。
Read/Write Through 更新模式 缓存由数据库代理。 缓存和数据库为一体。
wirte 更新模式 直接写数据库， 通过中间件（精卫）写入缓存。
异步处理 异步通讯的设计模式 ： 提高系统的稳定性和容错能力。 增加整个系统的吞吐量，从而可以面对更高的并发，并可以从容地利用好现有的系统资源。
当你在做一件事的时候，如果有别人来找你做其它事，你就会被打断而要去干别的事。而如果你可以统筹安排这些事情，本来五件事只需要 2 个小时，如果不能，或者老被别人打乱思路，那你可能就要花 5 个小时。异步处理任务可以让你更好地利用好时间和资源。利用好了时间和资源，性能自然就会提升上来。"><meta name=author content="Me"><link rel=canonical href=http://blog.chalme.top/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1-%E6%80%A7%E8%83%BD%E8%AE%BE%E8%AE%A1/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://blog.chalme.top/favicon_io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://blog.chalme.top/favicon_io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://blog.chalme.top/favicon_io/favicon-32x32.png><link rel=apple-touch-icon href=http://blog.chalme.top/favicon_io/apple-touch-icon.png><link rel=mask-icon href=http://blog.chalme.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="分布式关键设计 性能设计"><meta property="og:description" content="缓存 基本上来说，在分布式系统中最耗性能的地方就是最后端的数据库了。
一般来说，只要小心维护好，数据库四种操作（select、update、insert 和 delete）中的三个写操作 insert、update 和 delete 不太会出现性能问题（insert 一般不会有性能问题，update 和 delete 一般会有主键，所以也不会太慢）。除非索引建得太多，而数据库里的数据又太多，这三个操作才会变慢。 绝大多数情况下，select 是出现性能问题最大的地方。一方面，select 会有很多像 join、group、order、like 等这样丰富的语义，而这些语义是非常耗性能的；另一方面，大多数应用都是读多写少，所以加剧了慢查询的问题。 分布式系统中远程调用也会消耗很多资源，因为网络开销会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不需要太实时的数据）下，使用缓存是非常必要的事情。 设计的重点：
在分布式架构下，一般都需要一个外部的缓存集群。关于这个缓存集群，你需要保证的是内存要足够大，网络带宽也要好，因为缓存本质上是个内存和 IO 密集型的应用。 缓存的好坏要看命中率。缓存的命中率高说明缓存有效，一般来说命中率到 80% 以上就算很高了。当然，有的网络为了追求更高的性能，要做到 95% 以上，甚至可能会把数据库里的数据几乎全部装进缓存中。 缓存是通过牺牲强一致性来提高性能的，这世上任何事情都不是免费的 缓存数据的时间周期也需要好好设计 使用缓存的时候，一般会使用 LRU 策略 缓存是提高性能最好的方式，一般来说，缓存有以下三种模式。
Cache Aside 更新模式 失效：应用程序先从 Cache 取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 Cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。
当然，最好还是为缓存设置好过期时间。
为什么不去直接更新？ 主要是怕两个并发的写操作导致脏数据。
Cache Aside 就不会有并发问题了？ 比如，一个是读操作，但是没有命中缓存，就会到数据库中取数据。而此时来了一个写操作，写完数据库后，让缓存失效，然后之前的那个读操作再把老的数据放进去，所以会造成脏数据。
Read/Write Through 更新模式 缓存由数据库代理。 缓存和数据库为一体。
wirte 更新模式 直接写数据库， 通过中间件（精卫）写入缓存。
异步处理 异步通讯的设计模式 ： 提高系统的稳定性和容错能力。 增加整个系统的吞吐量，从而可以面对更高的并发，并可以从容地利用好现有的系统资源。
当你在做一件事的时候，如果有别人来找你做其它事，你就会被打断而要去干别的事。而如果你可以统筹安排这些事情，本来五件事只需要 2 个小时，如果不能，或者老被别人打乱思路，那你可能就要花 5 个小时。异步处理任务可以让你更好地利用好时间和资源。利用好了时间和资源，性能自然就会提升上来。"><meta property="og:type" content="article"><meta property="og:url" content="http://blog.chalme.top/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1-%E6%80%A7%E8%83%BD%E8%AE%BE%E8%AE%A1/"><meta property="og:image" content="http://blog.chalme.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-27T23:53:17+08:00"><meta property="article:modified_time" content="2023-01-27T23:53:17+08:00"><meta property="og:site_name" content="Chalme"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://blog.chalme.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="分布式关键设计 性能设计"><meta name=twitter:description content="缓存 基本上来说，在分布式系统中最耗性能的地方就是最后端的数据库了。
一般来说，只要小心维护好，数据库四种操作（select、update、insert 和 delete）中的三个写操作 insert、update 和 delete 不太会出现性能问题（insert 一般不会有性能问题，update 和 delete 一般会有主键，所以也不会太慢）。除非索引建得太多，而数据库里的数据又太多，这三个操作才会变慢。 绝大多数情况下，select 是出现性能问题最大的地方。一方面，select 会有很多像 join、group、order、like 等这样丰富的语义，而这些语义是非常耗性能的；另一方面，大多数应用都是读多写少，所以加剧了慢查询的问题。 分布式系统中远程调用也会消耗很多资源，因为网络开销会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不需要太实时的数据）下，使用缓存是非常必要的事情。 设计的重点：
在分布式架构下，一般都需要一个外部的缓存集群。关于这个缓存集群，你需要保证的是内存要足够大，网络带宽也要好，因为缓存本质上是个内存和 IO 密集型的应用。 缓存的好坏要看命中率。缓存的命中率高说明缓存有效，一般来说命中率到 80% 以上就算很高了。当然，有的网络为了追求更高的性能，要做到 95% 以上，甚至可能会把数据库里的数据几乎全部装进缓存中。 缓存是通过牺牲强一致性来提高性能的，这世上任何事情都不是免费的 缓存数据的时间周期也需要好好设计 使用缓存的时候，一般会使用 LRU 策略 缓存是提高性能最好的方式，一般来说，缓存有以下三种模式。
Cache Aside 更新模式 失效：应用程序先从 Cache 取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 Cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。
当然，最好还是为缓存设置好过期时间。
为什么不去直接更新？ 主要是怕两个并发的写操作导致脏数据。
Cache Aside 就不会有并发问题了？ 比如，一个是读操作，但是没有命中缓存，就会到数据库中取数据。而此时来了一个写操作，写完数据库后，让缓存失效，然后之前的那个读操作再把老的数据放进去，所以会造成脏数据。
Read/Write Through 更新模式 缓存由数据库代理。 缓存和数据库为一体。
wirte 更新模式 直接写数据库， 通过中间件（精卫）写入缓存。
异步处理 异步通讯的设计模式 ： 提高系统的稳定性和容错能力。 增加整个系统的吞吐量，从而可以面对更高的并发，并可以从容地利用好现有的系统资源。
当你在做一件事的时候，如果有别人来找你做其它事，你就会被打断而要去干别的事。而如果你可以统筹安排这些事情，本来五件事只需要 2 个小时，如果不能，或者老被别人打乱思路，那你可能就要花 5 个小时。异步处理任务可以让你更好地利用好时间和资源。利用好了时间和资源，性能自然就会提升上来。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://blog.chalme.top/posts/"},{"@type":"ListItem","position":2,"name":"分布式关键设计 性能设计","item":"http://blog.chalme.top/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1-%E6%80%A7%E8%83%BD%E8%AE%BE%E8%AE%A1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"分布式关键设计 性能设计","name":"分布式关键设计 性能设计","description":"缓存 基本上来说，在分布式系统中最耗性能的地方就是最后端的数据库了。\n一般来说，只要小心维护好，数据库四种操作（select、update、insert 和 delete）中的三个写操作 insert、update 和 delete 不太会出现性能问题（insert 一般不会有性能问题，update 和 delete 一般会有主键，所以也不会太慢）。除非索引建得太多，而数据库里的数据又太多，这三个操作才会变慢。 绝大多数情况下，select 是出现性能问题最大的地方。一方面，select 会有很多像 join、group、order、like 等这样丰富的语义，而这些语义是非常耗性能的；另一方面，大多数应用都是读多写少，所以加剧了慢查询的问题。 分布式系统中远程调用也会消耗很多资源，因为网络开销会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不需要太实时的数据）下，使用缓存是非常必要的事情。 设计的重点：\n在分布式架构下，一般都需要一个外部的缓存集群。关于这个缓存集群，你需要保证的是内存要足够大，网络带宽也要好，因为缓存本质上是个内存和 IO 密集型的应用。 缓存的好坏要看命中率。缓存的命中率高说明缓存有效，一般来说命中率到 80% 以上就算很高了。当然，有的网络为了追求更高的性能，要做到 95% 以上，甚至可能会把数据库里的数据几乎全部装进缓存中。 缓存是通过牺牲强一致性来提高性能的，这世上任何事情都不是免费的 缓存数据的时间周期也需要好好设计 使用缓存的时候，一般会使用 LRU 策略 缓存是提高性能最好的方式，一般来说，缓存有以下三种模式。\nCache Aside 更新模式 失效：应用程序先从 Cache 取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 Cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。\n当然，最好还是为缓存设置好过期时间。\n为什么不去直接更新？ 主要是怕两个并发的写操作导致脏数据。\nCache Aside 就不会有并发问题了？ 比如，一个是读操作，但是没有命中缓存，就会到数据库中取数据。而此时来了一个写操作，写完数据库后，让缓存失效，然后之前的那个读操作再把老的数据放进去，所以会造成脏数据。\nRead/Write Through 更新模式 缓存由数据库代理。 缓存和数据库为一体。\nwirte 更新模式 直接写数据库， 通过中间件（精卫）写入缓存。\n异步处理 异步通讯的设计模式 ： 提高系统的稳定性和容错能力。 增加整个系统的吞吐量，从而可以面对更高的并发，并可以从容地利用好现有的系统资源。\n当你在做一件事的时候，如果有别人来找你做其它事，你就会被打断而要去干别的事。而如果你可以统筹安排这些事情，本来五件事只需要 2 个小时，如果不能，或者老被别人打乱思路，那你可能就要花 5 个小时。异步处理任务可以让你更好地利用好时间和资源。利用好了时间和资源，性能自然就会提升上来。","keywords":["分布式架构","笔记"],"articleBody":"缓存 基本上来说，在分布式系统中最耗性能的地方就是最后端的数据库了。\n一般来说，只要小心维护好，数据库四种操作（select、update、insert 和 delete）中的三个写操作 insert、update 和 delete 不太会出现性能问题（insert 一般不会有性能问题，update 和 delete 一般会有主键，所以也不会太慢）。除非索引建得太多，而数据库里的数据又太多，这三个操作才会变慢。 绝大多数情况下，select 是出现性能问题最大的地方。一方面，select 会有很多像 join、group、order、like 等这样丰富的语义，而这些语义是非常耗性能的；另一方面，大多数应用都是读多写少，所以加剧了慢查询的问题。 分布式系统中远程调用也会消耗很多资源，因为网络开销会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不需要太实时的数据）下，使用缓存是非常必要的事情。 设计的重点：\n在分布式架构下，一般都需要一个外部的缓存集群。关于这个缓存集群，你需要保证的是内存要足够大，网络带宽也要好，因为缓存本质上是个内存和 IO 密集型的应用。 缓存的好坏要看命中率。缓存的命中率高说明缓存有效，一般来说命中率到 80% 以上就算很高了。当然，有的网络为了追求更高的性能，要做到 95% 以上，甚至可能会把数据库里的数据几乎全部装进缓存中。 缓存是通过牺牲强一致性来提高性能的，这世上任何事情都不是免费的 缓存数据的时间周期也需要好好设计 使用缓存的时候，一般会使用 LRU 策略 缓存是提高性能最好的方式，一般来说，缓存有以下三种模式。\nCache Aside 更新模式 失效：应用程序先从 Cache 取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 Cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。\n当然，最好还是为缓存设置好过期时间。\n为什么不去直接更新？ 主要是怕两个并发的写操作导致脏数据。\nCache Aside 就不会有并发问题了？ 比如，一个是读操作，但是没有命中缓存，就会到数据库中取数据。而此时来了一个写操作，写完数据库后，让缓存失效，然后之前的那个读操作再把老的数据放进去，所以会造成脏数据。\nRead/Write Through 更新模式 缓存由数据库代理。 缓存和数据库为一体。\nwirte 更新模式 直接写数据库， 通过中间件（精卫）写入缓存。\n异步处理 异步通讯的设计模式 ： 提高系统的稳定性和容错能力。 增加整个系统的吞吐量，从而可以面对更高的并发，并可以从容地利用好现有的系统资源。\n当你在做一件事的时候，如果有别人来找你做其它事，你就会被打断而要去干别的事。而如果你可以统筹安排这些事情，本来五件事只需要 2 个小时，如果不能，或者老被别人打乱思路，那你可能就要花 5 个小时。异步处理任务可以让你更好地利用好时间和资源。利用好了时间和资源，性能自然就会提升上来。\n这就好像邮递业务一样，你寄东西的时候，邮递公司会把大量的去往同一个方向的订单合并处理，并统一地调配物流交通工具，从而在整体上更为节省资源和时间。\n也就是说，merge 是把相同的操作合并，相同的读操作只读一次，相同的写操作，只写最后一次，而 sort 是把不同的操作排个序，这样可以让硬盘向一个方向转一次就可以把所有的数据读出来，而不是来来回回地转。这样可以极大地提高硬盘的吞吐率。 多说一句，就算是有延时，异步处理在用户体验上也可以给用户带来一个不错的用户体验，那就是用户可以有机会反悔之前的操作。 这就是异步系统所带来的好处——让我们的系统可以统一调度。\n设计： 首先，我们需要一个前台系统，把用户发来的请求一一记录下来，有点像请求日志。这样，我们的操作在数据库或是存储上只会有追加的操作，性能会很高。我们收到请求后，给客户端返回“收到请求，正在处理中”。\n然后，我们有个任务处理系统来真正地处理收到的这些请求。为了解耦，我们需要一个任务派发器，这里就会出来两个事，一个是推模型 Push，一个是拉模型 Pull。\n异步处理的设计要点： 异步处理中的事件驱动和事件溯源是两个比较关键的技术。 异步处理可能会因为一些故障导致我们的一些任务没有被处理，比如消息丢失，没有通知到，或通知到了，没有处理。有这一系列的问题，异步通知的方式需要任务处理方处理完成后，给任务发起方回传状态，这样确保不会有漏掉的。 发起方也需要有个定时任务，把一些超时没有回传状态的任务再重新做一遍，你可以认为这是异步系统中的 \" 对账 \" 功能。当然，如果要重做的话，就需要处理方支持幂等性处理。 异步处理的整体业务事务问题，也就是说，异步处理在处理任务的时候，并不知道能否处理成功，于是就会一步一步地处理，如果到最后一步不能成功，那么你就需要回滚。这个时候，需要走我们在弹力设计中说的补偿事务的流程。\n异步处理系统的本质是把被动的任务处理变成主动的任务处理，其本质是在对任务进行调度和统筹管理。\n事件溯源 主要想解决的问题是，我们可以看到数据库中的一个数据的值（状态），但我们完全不知道这个值是怎么得出来的。就像银行的存折一样，我们可以在银行的存折看到我们收支的所有记录，也能看得到每一笔记录后的余额。\n当然，如果我们有了所有的收支流水账的记录，我们完全不需要保存余额，因为我们只需要回放一下所有的收支事件，就可以得到最终的数据状态。这样一来，我们的系统就会变得非常简单，只需要追加不可修改的数据操作事件，而不是保存最终状态。除了可以提高性能和响应时间之外，还可以提供事务数据一致性，并保留了可以启用补偿操作的完整记录和历史记录。 还有一个好处，就是如果我们的代码里有了 bug，在记录状态的系统里，我们修改 bug 后还需要做数据修正。然而，在 Event Sourcing 的系统里，我们只需要把所有事件重新播放一遍就好了，因为整个系统没有状态了。\n事件不可变，并且可使用只追加操作进行存储。 用户界面、工作流或启动事件的进程可继续，处理事件的任务可在后台异步运行。 此外，处理事务期间不存在争用，这两点可极大提高应用程序的性能和可伸缩性。\n最重要的是，异步处理 + 事件溯源的方式，可以很好地让我们的整个系统进行任务的统筹安排、批量处理，可以让整体处理过程达到性能和资源的最大化利用。\n数据库扩展 读写分离 CQRS 这样的方法好处是：\n比较容易实现。数据库的 master-slave 的配置和服务框架里的读写分离都比较成熟，应用起来也很快。 可以很好地把各个业务隔离开来。不会因为一个业务把数据库拖死而导致所有的业务都死掉。 可以很好地分担数据库的读负载，毕竟读操作是最耗数据库 CPU 的操作。 CQRS 全称 Command and Query Responsibility Segregation，也就是命令与查询职责分离。其原理是，用户对于一个应用的操作可以分成两种，一种是 Command 也就是我们的写操作（增，删，改），另一种是 Query 操作（查），也就是读操作。Query 操作基本上是在做数据整合显现，而 Command 操作这边会有更重的业务逻辑。分离开这两种操作可以在语义上做好区分。\n分库分表 Sharding 影响数据库最大的性能问题有两个，一个是对数据库的操作，一个是数据库中数据的大小。\n对于前者，我们需要从业务上来优化。一方面，简化业务，不要在数据库上做太多的关联查询，而对于一些更为复杂的用于做报表或是搜索的数据库操作，应该把其移到更适合的地方。比如，用 ElasticSearch 来做查询，用 Hadoop 或别的数据分析软件来做报表分析。 对于后者，如果数据库里的数据越来越多，那么也会影响我们的数据操作。而且，对于我们的分布式系统来说，后端服务都可以做成分布式的，而数据库最好也是可以拆开成分布式的。读写分离也因为数据库里的数据太多而变慢，于是，分库分表就成了我们必须用的手段。 带来的问题：\nMax/Min/Count 这样的操作。 合并返回 join 事务 分库分片策略：\n租户 ID 按数据的种类来分 通过范围来分 通过哈希散列算法来分（比如：主键 id % 3 之类的算法。）此策略的目的是降低形成热点的可能性（接收不成比例的负载的分片）。 分片模式选择：\n数据库分片必须考虑业务，从业务的角度入手，而不是从技术的角度入手，如果你不清楚业务，那么无法做出好的分片策略。 请只考虑业务分片。请不要走哈希散列的分片方式，除非有个人拿着刀把你逼到墙角，你马上就有生命危险，你才能走哈希散列的分片方式。 设计重点： 在一个单体的库上做读写分离或是做分片都是一件治标不治本的事，真正治本的方法就是**要和服务一起拆解。**有两种分片模式，一种是水平分片，一种是垂直分片。\n水平分片需要有以下一些注意事项：\n随着数据库中数据的变化，我们有可能需要定期重新平衡分片，以保证均匀分布并降低形成热点的可能性。 减少平衡的次数。 快速重新平衡分片的工具和脚本。 分片是静态的，而数据的访问则是不可预期的，可能需要经常性地调整我们的分片，这样一来成本太高。所以，我们最好使用一个索引表的方式来进行分片。 数据分片后，我们很难在分片之间保持引用完整性和一致性，也就是所谓的跨分片的事务，因此应尽量减少会影响多个分片中的数据的操作。如果应用程序必须跨分片修改数据，那么我们需要评估一致性以及评估是否采用两阶段提交的方式。 配置和管理大量分片可能是一个挑战。在做相应的变更时，一定要先从生产线上拉出数据，然后根据数据计划好新的分片方式，并做好相当的测试工作。否则，这个事出了问题会是一个灾难性的问题。 秒杀 场景： “秒杀”其实是商家为了促销，使用非常低的价格销售商品，比如，1 元卖 iPhone，100 台，于是来了一百万人抢购。\n用户或产品的角度：\n首先，你需要一个秒杀的 landing page，在这个秒杀页上有一个倒计时的按钮。 一旦这个倒计时的时间到了，按钮就被点亮，让你可以点击按钮下单。 一般来说下单时需要你填写一个校验码，以防止是机器来抢。 细节： 倒计时时间需要校准； 需要向后端发送有没有开始， 如果开始， 返回前端一个 URL。\n技术挑战：\n100 万的同时并发会导致我们的网站瞬间就崩溃了。 网络带宽、100w 的 TPS 需要非常多的机器。 所有的请求都会集中在同一条数据库记录上，无论是怎么分库分表，还是使用了分布式数据库都无济于事，因为你面对的是单条的热点数据。 技术方案：\n**CDN。**上百个 CDN 的边缘结点，于是就能够扛得住。 我们需要把小服务部署到 CDN 结点上去。当前端页面来问开没开始时，这个小服务除了告诉前端开没开始外，它还可以统计下有多少人在线。 假设，我们知道有大约 100 万的人在线等着抢，那么，在我们快要开始的时候，由数据中心向各个部署在 CDN 结点上的小服务上传递一个概率值，比如说是 0.02%。 过滤用户请求。 其他实例： 12306 抢票 场景： 他们完全不知道用户来是要买哪张火车票的。不知道这个信息，很不好过滤用户，而且用户在买票前需要有很多查询操作，然后在查询中选择自己的车票。\n方案：\n12306 最好的应对方式，除了不要一次把所有的票放出来，而是分批在不同的时间段把票放出来，这样可以让人们不要集中在一个时间点来抢票，做到人肉分流，可以降低一些并发度。 12306 最好是用预售的方式，让大家把自己的购票先输入到系统中。系统并不真正放票，而是把大家的需求都收集好，然后做整体统筹安排，该增加车次的增加车次，该加车厢的加车厢，这样可以确保大家都能走。实在不行，那就抽签了。 更多的思考 场景： 双 11 那样，想尽可能多地卖出商品，那么就不像秒杀了。这是要尽可能多地收订单，但又不能超过库存，其中还有大量的银行支付，各大仓库的库存查询和分配，这些都是非常慢的操作。为了保证一致性，还要能够扛得住像双 11 这样的大规模并发访问，那么，应该怎么做呢？\n方案： 这个时候就需要认认真真地做高并发的架构和测试了，需要各个系统把自己的性能调整上去，还要小心地做性能规划，更要把分布式的弹力设计做好，最后是要不停地做性能测试，找到整个架构的系统瓶颈，然后不断地做水平扩展，以解决大规模的并发。\n小结 像我们用边缘结点来解决秒杀这样的场景的玩法，是否也有一定的普适性？这里，我想说，一定是有的。 更好的性能，成本。\n边缘计算 所谓边缘计算， 它是相对于数据中心而言。数据中心喜欢把所有的服务放在一个机房里集中处理用户的数据和请求，集中式部署一方面便于管理和运维，另一方面也便于服务间的通讯有一个比较好的网络保障。的确没错。不过，我们依然需要像CDN 这样的边缘式的内容发布网络，把我们的静态内容推到离用户最近的地方，然后获得更好的性能。\n为什么要有边缘计算 从趋势上： 整个计算机发展的本质就是我们人类生活信息化建设的过程。 这个过程中，计算机硬件的发展也是非常迅猛的。CPU 的处理速度，硬盘的大小和速度，网络的带宽和速度都在拼命地升级和降价。我们用越来越低的成本，获得越来越快的速度、越来越大的带宽、越来越快的存储…… 所有的这一切，其实都是和信息还有数据有关。我们的信息和数据越来越多，越来越大，所以，我们需要更好、更快、更便宜的硬件和基础设施。这个演化过程中，在我参加工作这 20 年来就没有停止过，而且，我也不认为未来会停下来，这个过程只会越来越快。 我们可以看到，数量越来越大，分析结果的速度需要越来越快，这两个需求，只会把我们逼到边缘计算上去。 如果你还是在数据中心处理，你会发现你的成本只会越来越高，到一定时候就完全玩不下去了。\n从成本： 根据我过去服务过的 40 多家公司的经验，可以看到如下的投入：\n几十万用户的公司，只需要处理百级 QPS 的量，只需要 10 台左右的服务器； 上百万用户的公司，只需要处理千级 QPS 的量，需要有 50 台左右的服务器； 上千万用户的公司，需要处理万级到十万级 QPS 的量，需要 700 台左右的服务器； 上亿用户的公司，其需要处理百万级 QPS 的量，需要上万台的服务器。 边缘计算的业务场景 处理一些实时响应的业务。它和用户靠得很近，所以可以实时响应用户的一些本地请求，比如，某公司的人脸门禁系统、共享单车的开锁。 处理一些简单的业务逻辑。比如像秒杀、抢红包这样的业务场景。 收集并结构化数据。比如，把视频中的车牌信息抠出来，转成文字，传回数据中心。 实时设备监控。主要是线下设备的数据采集和监控。 。。。\n关键技术 API Gateway Serverless/FaaS。就是服务函数化，这个技术就像是 AWS Lambda 服务一样，你写好一个函数，然后不用关心这个函数运行在哪里，直接发布就好了。然后就可以用了。 ","wordCount":"281","inLanguage":"en","datePublished":"2023-01-27T23:53:17+08:00","dateModified":"2023-01-27T23:53:17+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://blog.chalme.top/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1-%E6%80%A7%E8%83%BD%E8%AE%BE%E8%AE%A1/"},"publisher":{"@type":"Organization","name":"Chalme","logo":{"@type":"ImageObject","url":"http://blog.chalme.top/favicon_io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://blog.chalme.top/ accesskey=h title="Chalme (Alt + H)"><img src=http://blog.chalme.top/favicon_io/apple-touch-icon.png alt aria-label=logo height=35>Chalme</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://blog.chalme.top/archives title=Archive><span>Archive</span></a></li><li><a href=http://blog.chalme.top/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://blog.chalme.top/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://blog.chalme.top/>Home</a>&nbsp;»&nbsp;<a href=http://blog.chalme.top/posts/>Posts</a></div><h1 class=post-title>分布式关键设计 性能设计</h1><div class=post-meta><span title='2023-01-27 23:53:17 +0800 +0800'>January 27, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;281 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/chalme/hugo_blog/blob/main/content/posts/%e5%88%86%e5%b8%83%e5%bc%8f/%e5%88%86%e5%b8%83%e5%bc%8f%e5%85%b3%e9%94%ae%e8%ae%be%e8%ae%a1-%e6%80%a7%e8%83%bd%e8%ae%be%e8%ae%a1.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#缓存>缓存</a><ul><li><a href=#cache-aside-更新模式>Cache Aside 更新模式</a></li><li><a href=#readwrite-through-更新模式>Read/Write Through 更新模式</a></li><li><a href=#wirte-更新模式>wirte 更新模式</a></li></ul></li><li><a href=#异步处理>异步处理</a><ul><li><a href=#事件溯源>事件溯源</a></li></ul></li><li><a href=#数据库扩展>数据库扩展</a><ul><li><a href=#读写分离-cqrs>读写分离 CQRS</a></li><li><a href=#分库分表-sharding>分库分表 Sharding</a></li></ul></li><li><a href=#秒杀>秒杀</a><ul><li><a href=#更多的思考>更多的思考</a></li><li><a href=#小结>小结</a></li></ul></li><li><a href=#边缘计算>边缘计算</a><ul><li><a href=#为什么要有边缘计算>为什么要有边缘计算</a></li><li><a href=#边缘计算的业务场景>边缘计算的业务场景</a></li><li><a href=#关键技术>关键技术</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=缓存>缓存<a hidden class=anchor aria-hidden=true href=#缓存>#</a></h2><p>基本上来说，在分布式系统中最耗性能的地方就是最后端的数据库了。</p><ol><li>一般来说，只要小心维护好，数据库四种操作（select、update、insert 和 delete）中的三个写操作 insert、update 和 delete 不太会出现性能问题（insert 一般不会有性能问题，update 和 delete 一般会有主键，所以也不会太慢）。除非索引建得太多，而数据库里的数据又太多，这三个操作才会变慢。</li><li>绝大多数情况下，select 是出现性能问题最大的地方。<strong>一方面，select 会有很多像 join、group、order、like 等这样丰富的语义，而这些语义是非常耗性能的</strong>；<strong>另一方面，大多数应用都是读多写少，所以加剧了慢查询的问题。</strong></li></ol><p>分布式系统中远程调用也会消耗很多资源，因为网络开销会导致整体的响应时间下降。为了挽救这样的性能开销，在业务允许的情况（不需要太实时的数据）下，使用缓存是非常必要的事情。
设计的重点：</p><ol><li>在分布式架构下，一般都需要一个外部的缓存集群。关于这个缓存集群，你需要保证的是<strong>内存要足够大，网络带宽也要好</strong>，因为缓存本质上是个内存和 IO 密集型的应用。</li><li><strong>缓存的好坏要看命中率</strong>。缓存的命中率高说明缓存有效，一般来说命中率到 80% 以上就算很高了。当然，有的网络为了追求更高的性能，要做到 95% 以上，甚至可能会把数据库里的数据几乎全部装进缓存中。</li><li>缓存是通过<strong>牺牲强一致性</strong>来提高性能的，这世上任何事情都不是免费的</li><li>缓存数据的时间周期也需要好好设计</li><li>使用缓存的时候，一般会使用 LRU 策略</li></ol><p>缓存是提高性能最好的方式，一般来说，缓存有以下三种模式。</p><h3 id=cache-aside-更新模式>Cache Aside 更新模式<a hidden class=anchor aria-hidden=true href=#cache-aside-更新模式>#</a></h3><p><strong>失效</strong>：应用程序先从 Cache 取数据，如果没有得到，则从数据库中取数据，成功后，放到缓存中。
<strong>命中</strong>：应用程序从 Cache 中取数据，取到后返回。
<strong>更新</strong>：先把数据存到数据库中，成功后，再让缓存失效。</p><p>当然，最好还是<strong>为缓存设置好过期时间</strong>。</p><p><strong>为什么不去直接更新？</strong>
主要是怕两个并发的写操作导致脏数据。</p><p><strong>Cache Aside 就不会有并发问题了？</strong>
比如，一个是读操作，但是没有命中缓存，就会到数据库中取数据。而此时来了一个写操作，写完数据库后，让缓存失效，然后之前的那个读操作再把老的数据放进去，所以会造成脏数据。</p><h3 id=readwrite-through-更新模式>Read/Write Through 更新模式<a hidden class=anchor aria-hidden=true href=#readwrite-through-更新模式>#</a></h3><p>缓存由数据库代理。 缓存和数据库为一体。</p><h3 id=wirte-更新模式>wirte 更新模式<a hidden class=anchor aria-hidden=true href=#wirte-更新模式>#</a></h3><p>直接写数据库， 通过中间件（精卫）写入缓存。</p><h2 id=异步处理>异步处理<a hidden class=anchor aria-hidden=true href=#异步处理>#</a></h2><p>异步通讯的设计模式 ： 提高系统的稳定性和容错能力。 增加整个系统的吞吐量，从而可以面对更高的并发，并可以从容地利用好现有的系统资源。</p><p>当你在做一件事的时候，如果有别人来找你做其它事，你就会被打断而要去干别的事。而如果你可以统筹安排这些事情，本来五件事只需要 2 个小时，如果不能，或者老被别人打乱思路，那你可能就要花 5 个小时。异步处理任务可以让你更好地利用好时间和资源。利用好了时间和资源，性能自然就会提升上来。</p><p>这就好像邮递业务一样，你寄东西的时候，邮递公司会把大量的去往同一个方向的订单合并处理，并统一地调配物流交通工具，从而在整体上更为节省资源和时间。</p><p>也就是说，merge 是把相同的操作合并，相同的读操作只读一次，相同的写操作，只写最后一次，而 sort 是把不同的操作排个序，这样可以让硬盘向一个方向转一次就可以把所有的数据读出来，而不是来来回回地转。这样可以极大地提高硬盘的吞吐率。
多说一句，就算是有延时，异步处理在用户体验上也可以给用户带来一个不错的用户体验，那就是用户可以有机会反悔之前的操作。
<strong>这就是异步系统所带来的好处——让我们的系统可以统一调度。</strong></p><p><strong>设计：</strong>
首先，我们需要一个前台系统，把用户发来的请求一一记录下来，有点像请求日志。这样，我们的操作在数据库或是存储上只会有追加的操作，性能会很高。我们收到请求后，给客户端返回“收到请求，正在处理中”。</p><p>然后，我们有个任务处理系统来真正地处理收到的这些请求。为了解耦，我们需要一个任务派发器，这里就会出来两个事，一个是推模型 Push，一个是拉模型 Pull。</p><p>异步处理的设计要点：
异步处理中的<strong>事件驱动</strong>和<strong>事件溯源</strong>是两个比较关键的技术。
异步处理可能会因为一些故障导致我们的一些任务没有被处理，比如消息丢失，没有通知到，或通知到了，没有处理。有这一系列的问题，异步通知的方式需要任务处理方处理完成后，给任务发起方回传状态，这样确保不会有漏掉的。
发起方也需要有个定时任务，把一些超时没有回传状态的任务再重新做一遍，你可以认为这是异步系统中的 " 对账 " 功能。当然，如果要重做的话，就需要处理方支持幂等性处理。
异步处理的整体业务事务问题，也就是说，异步处理在处理任务的时候，并不知道能否处理成功，于是就会一步一步地处理，如果到最后一步不能成功，那么你就需要回滚。这个时候，需要走我们在弹力设计中说的<strong>补偿事务的流程</strong>。</p><p>异步处理系统的本质是把被动的任务处理变成主动的任务处理，其本质是<strong>在对任务进行调度和统筹管理。</strong></p><h3 id=事件溯源>事件溯源<a hidden class=anchor aria-hidden=true href=#事件溯源>#</a></h3><p><strong>主要想解决的问题是</strong>，我们可以看到数据库中的一个数据的值（状态），但我们完全不知道这个值是怎么得出来的。就像银行的存折一样，我们可以在银行的存折看到我们收支的所有记录，也能看得到每一笔记录后的余额。</p><p>当然，如果我们有了所有的收支流水账的记录，我们完全不需要保存余额，因为我们只需要<strong>回放一下所有的收支事件，就可以得到最终的数据状态</strong>。这样一来，我们的系统就会变得非常简单，<strong>只需要追加不可修改的数据操作事件，而不是保存最终状态</strong>。<strong>除了可以提高性能和响应时间之外，还可以提供事务数据一致性，并保留了可以启用补偿操作的完整记录和历史记录。</strong>
还有一个好处，<strong>就是如果我们的代码里有了 bug，在记录状态的系统里，我们修改 bug 后还需要做数据修正。然而，在 Event Sourcing 的系统里，我们只需要把所有事件重新播放一遍就好了，因为整个系统没有状态了。</strong></p><p>事件不可变，并且可使用只追加操作进行存储。 用户界面、工作流或启动事件的进程可继续，处理事件的任务可在后台异步运行。 此外，处理事务期间不存在争用，这两点可极大提高应用程序的性能和可伸缩性。</p><p>最重要的是，<strong>异步处理 + 事件溯源的方式，可以很好地让我们的整个系统进行任务的统筹安排、批量处理，可以让整体处理过程达到性能和资源的最大化利用。</strong></p><h2 id=数据库扩展>数据库扩展<a hidden class=anchor aria-hidden=true href=#数据库扩展>#</a></h2><h3 id=读写分离-cqrs>读写分离 CQRS<a hidden class=anchor aria-hidden=true href=#读写分离-cqrs>#</a></h3><p><img loading=lazy src=http://qiniu.chalme.top/blog/20230127/HdsYQE.jpg alt=HdsYQE>
这样的方法好处是：</p><ol><li>比较容易实现。数据库的 master-slave 的配置和服务框架里的读写分离都比较成熟，应用起来也很快。</li><li>可以很好地把各个业务隔离开来。不会因为一个业务把数据库拖死而导致所有的业务都死掉。</li><li>可以很好地分担数据库的读负载，毕竟读操作是最耗数据库 CPU 的操作。</li></ol><p>CQRS 全称 Command and Query Responsibility Segregation，也就是命令与查询职责分离。其原理是，用户对于一个应用的操作可以分成两种，一种是 Command 也就是我们的写操作（增，删，改），另一种是 Query 操作（查），也就是读操作。Query 操作基本上是在做数据整合显现，而 Command 操作这边会有更重的业务逻辑。分离开这两种操作可以在语义上做好区分。</p><h3 id=分库分表-sharding>分库分表 Sharding<a hidden class=anchor aria-hidden=true href=#分库分表-sharding>#</a></h3><p>影响数据库最大的性能问题有两个，一个是对数据库的操作，一个是数据库中数据的大小。</p><ol><li>对于前者，我们需要从业务上来优化。一方面，简化业务，不要在数据库上做太多的关联查询，而对于一些更为复杂的用于做报表或是搜索的数据库操作，应该把其移到更适合的地方。比如，用 ElasticSearch 来做查询，用 Hadoop 或别的数据分析软件来做报表分析。</li><li>对于后者，如果数据库里的数据越来越多，那么也会影响我们的数据操作。而且，对于我们的分布式系统来说，后端服务都可以做成分布式的，而数据库最好也是可以拆开成分布式的。读写分离也因为数据库里的数据太多而变慢，于是，分库分表就成了我们必须用的手段。</li></ol><p>带来的问题：</p><ol><li>Max/Min/Count 这样的操作。 合并返回</li><li>join</li><li>事务</li></ol><p>分库分片策略：</p><ol><li>租户 ID</li><li>按数据的种类来分</li><li>通过范围来分</li><li>通过哈希散列算法来分（比如：主键 id % 3 之类的算法。）此策略的目的是降低形成热点的可能性（接收不成比例的负载的分片）。</li></ol><p>分片模式选择：</p><ol><li>数据库分片必须考虑业务，从业务的角度入手，而不是从技术的角度入手，如果你不清楚业务，那么无法做出好的分片策略。</li><li>请只考虑业务分片。请不要走哈希散列的分片方式，除非有个人拿着刀把你逼到墙角，你马上就有生命危险，你才能走哈希散列的分片方式。</li></ol><p>设计重点：
在一个单体的库上做读写分离或是做分片都是一件治标不治本的事，真正治本的方法就是**要和服务一起拆解。**有两种分片模式，一种是水平分片，一种是垂直分片。</p><p>水平分片需要有以下一些注意事项：</p><ol><li>随着数据库中数据的变化，我们有可能需要定期重新平衡分片，以保证均匀分布并降低形成热点的可能性。<ol><li>减少平衡的次数。</li><li>快速重新平衡分片的工具和脚本。</li></ol></li><li><strong>分片是静态的，而数据的访问则是不可预期的</strong>，可能需要经常性地调整我们的分片，这样一来成本太高。所以，我们最好<strong>使用一个索引表的方式来进行分片</strong>。</li><li>数据分片后，我们很难在分片之间保持引用完整性和一致性，也就是所谓的跨分片的事务，因此应尽量减少会影响多个分片中的数据的操作。如果应用程序必须跨分片修改数据，那么我们需要评估一致性以及评估是否采用两阶段提交的方式。</li><li>配置和管理大量分片可能是一个挑战。在做相应的变更时，一定要先从生产线上拉出数据，然后根据数据计划好新的分片方式，并做好相当的测试工作。否则，这个事出了问题会是一个灾难性的问题。</li></ol><h2 id=秒杀>秒杀<a hidden class=anchor aria-hidden=true href=#秒杀>#</a></h2><p><strong>场景：</strong>
“秒杀”其实是商家为了促销，使用非常低的价格销售商品，比如，1 元卖 iPhone，100 台，于是来了一百万人抢购。</p><p>用户或产品的角度：</p><ol><li>首先，你需要一个秒杀的 landing page，在这个秒杀页上有一个倒计时的按钮。</li><li>一旦这个倒计时的时间到了，按钮就被点亮，让你可以点击按钮下单。</li><li>一般来说下单时需要你填写一个校验码，以防止是机器来抢。</li></ol><p>细节： 倒计时时间需要校准； 需要向后端发送有没有开始， 如果开始， 返回前端一个 URL。</p><p><strong>技术挑战：</strong></p><ol><li>100 万的同时并发会导致我们的网站瞬间就崩溃了。 <strong>网络带宽、100w 的 TPS 需要非常多的机器。</strong></li><li>所有的请求都会集中在同一条数据库记录上，无论是怎么分库分表，还是使用了分布式数据库都无济于事，因为你面对的是单条的热点数据。</li></ol><p><strong>技术方案：</strong></p><ol><li>**CDN。**上百个 CDN 的边缘结点，于是就能够扛得住。</li><li>我们需要把<strong>小服务部署到 CDN 结点上去</strong>。当前端页面来问开没开始时，这个小服务除了告诉前端开没开始外，它还可以统计下有多少人在线。</li><li>假设，<strong>我们知道有大约 100 万的人在线等着抢</strong>，那么，在我们快要开始的时候，由<strong>数据中心向各个部署在 CDN 结点上的小服务上传递一个概率值，比如说是 0.02%</strong>。 过滤用户请求。</li></ol><p><strong>其他实例：</strong>
12306 抢票
<strong>场景：</strong> 他们完全不知道用户来是要买哪张火车票的。不知道这个信息，很不好过滤用户，而且用户在买票前需要有很多查询操作，然后在查询中选择自己的车票。</p><p><strong>方案：</strong></p><ol><li>12306 最好的应对方式，除了不要一次把所有的票放出来，而是分批在不同的时间段把票放出来，这样可以让人们不要集中在一个时间点来抢票，做到人肉分流，可以降低一些并发度。</li><li>12306 最好是用预售的方式，让大家把自己的购票先输入到系统中。系统并不真正放票，而是把大家的需求都收集好，然后做整体统筹安排，该增加车次的增加车次，该加车厢的加车厢，这样可以确保大家都能走。实在不行，那就抽签了。</li></ol><h3 id=更多的思考>更多的思考<a hidden class=anchor aria-hidden=true href=#更多的思考>#</a></h3><p><strong>场景：</strong>
<strong>双 11 那样，想尽可能多地卖出商品，那么就不像秒杀了</strong>。这是要尽可能多地收订单，但又不能超过库存，其中还有大量的银行支付，各大仓库的库存查询和分配，这些都是非常慢的操作。为了保证一致性，还要能够扛得住像双 11 这样的大规模并发访问，那么，应该怎么做呢？</p><p><strong>方案：</strong>
这个时候就需要<strong>认认真真地做高并发的架构和测试</strong>了，需要各个系统把自己的性能调整上去，还要小心地做<strong>性能规划，更要把分布式的弹力设计</strong>做好，最后是要不停地做性能测试，找到整个架构的系统瓶颈，然后不断地做水平扩展，以解决大规模的并发。</p><h3 id=小结>小结<a hidden class=anchor aria-hidden=true href=#小结>#</a></h3><p>像我们用边缘结点来解决秒杀这样的场景的玩法，是否也有一定的普适性？这里，我想说，一定是有的。
<strong>更好的性能，成本。</strong></p><h2 id=边缘计算>边缘计算<a hidden class=anchor aria-hidden=true href=#边缘计算>#</a></h2><p>所谓边缘计算，
它是相对于数据中心而言。<strong>数据中心喜欢把所有的服务放在一个机房里集中处理用户的数据和请求，集中式部署一方面便于管理和运维，另一方面也便于服务间的通讯有一个比较好的网络保障。<strong>的确没错。不过，我们依然需要像</strong>CDN 这样的边缘式的内容发布网络，把我们的静态内容推到离用户最近的地方</strong>，然后获得更好的性能。</p><h3 id=为什么要有边缘计算>为什么要有边缘计算<a hidden class=anchor aria-hidden=true href=#为什么要有边缘计算>#</a></h3><p>从趋势上：
整个计算机发展的本质就是我们人类生活信息化建设的过程。
这个过程中，计算机硬件的发展也是非常迅猛的。CPU 的处理速度，硬盘的大小和速度，网络的带宽和速度都在拼命地升级和降价。我们用越来越低的成本，获得越来越快的速度、越来越大的带宽、越来越快的存储……
所有的这一切，其实都是和信息还有数据有关。我们的信息和数据越来越多，越来越大，所以，我们需要更好、更快、更便宜的硬件和基础设施。这个演化过程中，在我参加工作这 20 年来就没有停止过，而且，我也不认为未来会停下来，这个过程只会越来越快。
<img loading=lazy src=http://qiniu.chalme.top/blog/20230127/IKPSe1.jpg alt=IKPSe1></p><p>我们可以看到，<strong>数量越来越大，分析结果的速度需要越来越快，这两个需求，只会把我们逼到边缘计算上去。</strong> 如果你还是在数据中心处理，你会发现你的成本只会越来越高，到一定时候就完全玩不下去了。</p><p>从成本：
根据我过去服务过的 40 多家公司的经验，可以看到如下的投入：</p><ol><li>几十万用户的公司，只需要处理百级 QPS 的量，只需要 10 台左右的服务器；</li><li>上百万用户的公司，只需要处理千级 QPS 的量，需要有 50 台左右的服务器；</li><li>上千万用户的公司，需要处理万级到十万级 QPS 的量，需要 700 台左右的服务器；</li><li>上亿用户的公司，其需要处理百万级 QPS 的量，需要上万台的服务器。</li></ol><h3 id=边缘计算的业务场景>边缘计算的业务场景<a hidden class=anchor aria-hidden=true href=#边缘计算的业务场景>#</a></h3><ol><li>处理一些实时响应的业务。它和用户靠得很近，所以可以实时响应用户的一些本地请求，比如，某公司的人脸门禁系统、共享单车的开锁。</li><li>处理一些简单的业务逻辑。比如像秒杀、抢红包这样的业务场景。</li><li>收集并结构化数据。比如，把视频中的车牌信息抠出来，转成文字，传回数据中心。</li><li>实时设备监控。主要是线下设备的数据采集和监控。</li></ol><p>。。。</p><h3 id=关键技术>关键技术<a hidden class=anchor aria-hidden=true href=#关键技术>#</a></h3><ol><li>API Gateway</li><li>Serverless/FaaS。就是服务函数化，这个技术就像是 AWS Lambda 服务一样，你写好一个函数，然后不用关心这个函数运行在哪里，直接发布就好了。然后就可以用了。</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=http://blog.chalme.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/>分布式架构</a></li><li><a href=http://blog.chalme.top/tags/%E7%AC%94%E8%AE%B0/>笔记</a></li></ul><nav class=paginav><a class=prev href=http://blog.chalme.top/posts/%E7%AE%97%E6%B3%95%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/><span class=title>« Prev</span><br><span>算法与数据结构</span></a>
<a class=next href=http://blog.chalme.top/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1-%E7%AE%A1%E7%90%86%E8%AE%BE%E8%AE%A1/><span class=title>Next »</span><br><span>分布式关键设计 管理设计</span></a></nav></footer><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://pc-chalme.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2023 <a href=http://blog.chalme.top/>Chalme</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>